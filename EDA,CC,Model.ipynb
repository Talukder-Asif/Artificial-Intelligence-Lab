{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Talukder-Asif/Artificial-Intelligence-Lab/blob/main/EDA%2CCC%2CModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sqpYgqXSyra",
        "outputId": "f8cb87c7-8790-44c9-f2a9-e9a8fcfc5853"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.11/dist-packages (24.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 24.1.2\n",
            "    Uninstalling pip-24.1.2:\n",
            "      Successfully uninstalled pip-24.1.2\n",
            "Successfully installed pip-25.2\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade pip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imbalanced-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LZw6-n8TzrG",
        "outputId": "aedbc459-5ece-4ecf-8e6c-1902cb10b6b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: numpy<3,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (2.0.2)\n",
            "Requirement already satisfied: scipy<2,>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.16.1)\n",
            "Requirement already satisfied: scikit-learn<2,>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.6.1)\n",
            "Requirement already satisfied: sklearn-compat<1,>=0.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (0.1.3)\n",
            "Requirement already satisfied: joblib<2,>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl<4,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from imbalanced-learn) (3.6.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDRHkahsT688",
        "outputId": "a7047d73-4fdb-4e87-8d98-0db594eb076d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install scikeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52qsvjDWT86P",
        "outputId": "4b15d5cf-c351-4c59-8304-add6a4cdc856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikeras\n",
            "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from scikeras) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from scikeras) (1.6.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (2.0.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (3.14.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.17.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (0.5.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras>=3.2.0->scikeras) (25.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.16.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from optree->keras>=3.2.0->scikeras) (4.14.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.2.0->scikeras) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n",
            "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69E3BZu_UOIc",
        "outputId": "da075296-989c-44a7-951e-c18fc7a6ccad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.23.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.16.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import scipy\n",
        "import time\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.stats import pearsonr\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.model_selection import GridSearchCV, train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense,Dropout,Activation,BatchNormalization\n",
        "from scikeras import wrappers\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc as auc_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.model_selection import cross_val_score,cross_val_predict, cross_validate\n",
        "from sklearn.metrics import make_scorer,precision_score, recall_score, f1_score, roc_auc_score, accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "l8Fi_ZgPUcH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os"
      ],
      "metadata": {
        "id": "w5Ng-kxR992Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "outputId": "a4a8c193-efa0-4a39-ea56-b60c4e7e2b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-616350279.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "file_path =(\"/content/kidney_disease (2).csv\")\n",
        "df = pd.read_csv(file_path)\n",
        "df"
      ],
      "metadata": {
        "id": "65SyskVRVEuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop(['id'], axis=1)\n",
        "df.head(5)"
      ],
      "metadata": {
        "id": "iHWwDmPlaHLm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)\n"
      ],
      "metadata": {
        "id": "ZjzTtDHJanfi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA"
      ],
      "metadata": {
        "id": "LT34jHe0k2W7"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xcg7VBWwk7f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WbcT2thSk7SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EDA_END"
      ],
      "metadata": {
        "id": "V2TcfrASk5Jq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Bm2hSAxMk441"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWOk3-Cgk3E6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "_QXs62y0k2Ca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "CIApmdDVa19T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.value_counts('classification')"
      ],
      "metadata": {
        "id": "CCpr9CMOa-VA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.countplot(x='classification', data=df)\n",
        "plt.title('Number of samples of Dataset A')\n",
        "plt.xlabel('Diagnosis')\n",
        "plt.ylabel('Count')\n",
        "plt.savefig('Number of samples of Dataset A.pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CXPPH3gbKro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df[df['classification'] != 'ckd\\t']\n",
        "df.value_counts('classification')"
      ],
      "metadata": {
        "id": "mrbB562TbvOy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(columns=['classification'])\n"
      ],
      "metadata": {
        "id": "b-2rO1Wcb1z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "JzLSRnkecArC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "Mk3XPNFRjRCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_encoded = pd.get_dummies(df, columns=['pcv','wc','rc','htn','dm','cad', 'pe', 'ane', 'classification' ], drop_first=True)\n"
      ],
      "metadata": {
        "id": "raUmSdlcfOfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert 'bool' columns to int (True -> 1, False -> 0)\n",
        "bool_cols = df.select_dtypes(include='bool').columns\n",
        "df[bool_cols] = df[bool_cols].astype(int)\n",
        "\n",
        "# Convert 'object' columns to numeric using Label Encoding\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "object_cols = df.select_dtypes(include='object').columns\n",
        "\n",
        "for col in object_cols:\n",
        "    df[col] = df[col].astype(str)  # Ensure all values are strings\n",
        "    df[col] = label_encoder.fit_transform(df[col])\n",
        "\n",
        "# Check the result\n",
        "print(df.head())\n",
        "print(df.dtypes)"
      ],
      "metadata": {
        "id": "H6qcHhUgf2Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "dwX05SURfVK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "id": "UgJw1aeO95N7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.shape[1]\n",
        "\n",
        "print(\"Number of columns:\", num_cols)"
      ],
      "metadata": {
        "id": "jGCtzULr5Kl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = len(df.columns)  # ❌ This gives an integer"
      ],
      "metadata": {
        "id": "F7fo4_oJ5sNE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns"
      ],
      "metadata": {
        "id": "sSBf3LBK51Je"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols:\n",
        "    print(col)\n",
        "    print('Skew :', round(df[col].skew(), 2))\n",
        "    plt.figure(figsize = (15, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    df[col].hist(grid=False)\n",
        "    plt.ylabel('count')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    sns.boxplot(x=df[col])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "aphbGAEw32O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model training section"
      ],
      "metadata": {
        "id": "rYkNndN7-_Jr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = df.drop(columns=['classification'])\n",
        "y = df['classification']"
      ],
      "metadata": {
        "id": "GwRvA3n0_KUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x, y,test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "pVLx2XLz--vN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Impute missing values using the mean\n",
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "# feature normalized\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler= StandardScaler()\n",
        "X_train= scaler.fit_transform(X_train)\n",
        "X_test= scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "i_fMpWi-_V-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest"
      ],
      "metadata": {
        "id": "7zyGxOz5_vfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred = rf_model.predict(X_test)"
      ],
      "metadata": {
        "id": "IcevP1yQ_aLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")"
      ],
      "metadata": {
        "id": "F19jPePJ_iiq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree"
      ],
      "metadata": {
        "id": "I1liCjhY_sQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "dt_model = DecisionTreeClassifier(random_state=42)\n",
        "dt_model.fit(X_train, y_train)\n",
        "y_pred_dt = dt_model.predict(X_test)"
      ],
      "metadata": {
        "id": "gEIpUZ1D_oFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "precision_dt = precision_score(y_test, y_pred_dt)\n",
        "recall_dt = recall_score(y_test, y_pred_dt)\n",
        "f1_dt = f1_score(y_test, y_pred_dt)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_dt}\")\n",
        "print(f\"Precision: {precision_dt}\")\n",
        "print(f\"Recall: {recall_dt}\")\n",
        "print(f\"F1 Score: {f1_dt}\")"
      ],
      "metadata": {
        "id": "bC9D2blC_xnw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(X_train, y_train)\n",
        "y_pred_knn = knn_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Hv0A7yjA_2IW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_knn = accuracy_score(y_test, y_pred_knn)\n",
        "precision_knn = precision_score(y_test, y_pred_knn)\n",
        "recall_knn = recall_score(y_test, y_pred_knn)\n",
        "f1_knn = f1_score(y_test, y_pred_knn)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_knn}\")\n",
        "print(f\"Precision: {precision_knn}\")\n",
        "print(f\"Recall: {recall_knn}\")\n",
        "print(f\"F1 Score: {f1_knn}\")"
      ],
      "metadata": {
        "id": "IKn2sScsAkb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "4YY4uxNjAxg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)"
      ],
      "metadata": {
        "id": "P2vEGk_dAoQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr)\n",
        "recall_lr = recall_score(y_test, y_pred_lr)\n",
        "f1_lr = f1_score(y_test, y_pred_lr)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_lr}\")\n",
        "print(f\"Precision: {precision_lr}\")\n",
        "print(f\"Recall: {recall_lr}\")\n",
        "print(f\"F1 Score: {f1_lr}\")"
      ],
      "metadata": {
        "id": "aIdq-RisArMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adaboost"
      ],
      "metadata": {
        "id": "r4WfF9bCA1uj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "adaboost_model = AdaBoostClassifier(random_state=42)\n",
        "adaboost_model.fit(X_train, y_train)\n",
        "y_pred_ada = adaboost_model.predict(X_test)"
      ],
      "metadata": {
        "id": "s2zBUevNAuk-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_ada = accuracy_score(y_test, y_pred_ada)\n",
        "precision_ada = precision_score(y_test, y_pred_ada)\n",
        "recall_ada = recall_score(y_test, y_pred_ada)\n",
        "f1_ada = f1_score(y_test, y_pred_ada)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_ada}\")\n",
        "print(f\"Precision: {precision_ada}\")\n",
        "print(f\"Recall: {recall_ada}\")\n",
        "print(f\"F1 Score: {f1_ada}\")"
      ],
      "metadata": {
        "id": "cnIC3u5MA61-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bais"
      ],
      "metadata": {
        "id": "IuvEOigKBFK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "y_pred_nb = nb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "XI6C8I02A9nl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_nb = accuracy_score(y_test, y_pred_nb)\n",
        "precision_nb = precision_score(y_test, y_pred_nb)\n",
        "recall_nb = recall_score(y_test, y_pred_nb)\n",
        "f1_nb= f1_score(y_test, y_pred_nb)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_nb}\")\n",
        "print(f\"Precision: {precision_nb}\")\n",
        "print(f\"Recall: {recall_nb}\")\n",
        "print(f\"F1 Score: {f1_nb}\")"
      ],
      "metadata": {
        "id": "DxdRxOsTBBfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "O8HZ_ACHBOVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "svm_model = SVC(random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "y_pred_svm = svm_model.predict(X_test)"
      ],
      "metadata": {
        "id": "p9__w7bjBKf6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_svm= accuracy_score(y_test, y_pred_svm)\n",
        "precision_svm = precision_score(y_test, y_pred_svm)\n",
        "recall_svm = recall_score(y_test, y_pred_svm)\n",
        "f1_svm= f1_score(y_test, y_pred_svm)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_svm}\")\n",
        "print(f\"Precision: {precision_svm}\")\n",
        "print(f\"Recall: {recall_svm}\")\n",
        "print(f\"F1 Score: {f1_svm}\")"
      ],
      "metadata": {
        "id": "5QnZ7flBBP1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "XGBoost"
      ],
      "metadata": {
        "id": "w_CyJ2jZBZPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "xgboost_model = XGBClassifier(random_state=42)\n",
        "xgboost_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgboost_model.predict(X_test)"
      ],
      "metadata": {
        "id": "fWLlhBOqBSAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "# Calculate the metrics\n",
        "accuracy_xgb= accuracy_score(y_test, y_pred_xgb)\n",
        "precision_xgb = precision_score(y_test, y_pred_xgb)\n",
        "recall_xgb= recall_score(y_test, y_pred_xgb)\n",
        "f1_xgb= f1_score(y_test, y_pred_xgb)\n",
        "\n",
        "# Print the metrics\n",
        "print(f\"Accuracy: {accuracy_xgb}\")\n",
        "print(f\"Precision: {precision_xgb}\")\n",
        "print(f\"Recall: {recall_xgb}\")\n",
        "print(f\"F1 Score: {f1_xgb}\")"
      ],
      "metadata": {
        "id": "4JYJESdtBVy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANN"
      ],
      "metadata": {
        "id": "9gxwVRcSBcNF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define ANN model\n",
        "ann_model = Sequential()\n",
        "ann_model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "ann_model.add(Dropout(0.2))\n",
        "ann_model.add(Dense(32, activation='relu'))\n",
        "ann_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "ann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "ann_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "ann_predictions = ann_model.predict(X_test)\n",
        "y_pred_ann = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred_ann)\n",
        "precision = precision_score(y_test, y_pred_ann)\n",
        "recall = recall_score(y_test, y_pred_ann)\n",
        "f1 = f1_score(y_test, y_pred_ann)\n",
        "\n",
        "# Output results\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "print(f\"precision: {precision}\")\n",
        "print(f\"recall: {recall}\")\n",
        "print(f\"F1 score: {f1}\")"
      ],
      "metadata": {
        "id": "IS7dW3XsBYcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM"
      ],
      "metadata": {
        "id": "vgw_TE5zBo6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dropout, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "if len(X_train.shape) == 2:\n",
        "    X_train = np.array(X_train).reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
        "    X_test = np.array(X_test).reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "# Build LSTM model\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(150, activation='relu', return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(LSTM(150, activation='relu'))\n",
        "model_lstm.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model_lstm.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model_lstm.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model_lstm.predict(X_test)\n",
        "y_pred_lstm = (y_pred > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate accuracy, precision, recall, and F1-score\n",
        "accuracy = accuracy_score(y_test, y_pred_lstm)\n",
        "precision = precision_score(y_test, y_pred_lstm)\n",
        "recall = recall_score(y_test, y_pred_lstm)\n",
        "f1 = f1_score(y_test, y_pred_lstm)\n",
        "\n",
        "# Output results\n",
        "print(f\"accuracy: {accuracy}\")\n",
        "print(f\"precision: {precision}\")\n",
        "print(f\"recall: {recall}\")\n",
        "print(f\"F1 score: {f1}\")"
      ],
      "metadata": {
        "id": "Ey7Fuw0uBooL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RNN"
      ],
      "metadata": {
        "id": "ZzQD4D6KB2xP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Model names and their corresponding metrics\n",
        "models = ['RF', 'DT', 'KNN', 'LR', 'ADA', 'NB', 'SVM', 'XGB', 'ANN', 'LSTM', 'RNN']\n",
        "\n",
        "# Accuracy, Precision, Recall, F1 Score for each model (updated based on the provided data)\n",
        "accuracy = [100 * x for x in [\n",
        "    0.9307228915662651, 0.8855421686746988, 0.9186746987951807, 0.9367469879518072, 0.9246987951807228,\n",
        "    0.927710843373494, 0.927710843373494, 0.9397590361445783, 0.9307228915662651, 0.9246987951807228,\n",
        "    0.9216867469879518\n",
        "]]\n",
        "precision = [100 * x for x in [\n",
        "    0.9305135951661632, 0.9470198675496688, 0.9270516717325228, 0.9415384615384615, 0.9435736677115988,\n",
        "    0.9382716049382716, 0.927710843373494, 0.9444444444444444, 0.9305135951661632, 0.9353846153846154,\n",
        "    0.9272727272727272\n",
        "]]\n",
        "recall = [100 * x for x in [\n",
        "    1.0, 0.9285714285714286, 0.9902597402597403, 0.9935064935064936, 0.9772727272727273,\n",
        "    0.987012987012987, 1.0, 0.9935064935064936, 1.0, 0.987012987012987, 0.9935064935064936\n",
        "]]\n",
        "f1_score = [100 * x for x in [\n",
        "    0.9640062597809077, 0.9377049180327869, 0.957613814756672, 0.966824644549763, 0.960127591706539,\n",
        "    0.9620253164556962, 0.9625, 0.9683544303797469, 0.9640062597809077, 0.9605055292259084,\n",
        "    0.9592476489028213\n",
        "]]\n",
        "\n",
        "# Dummy error values for error bars (calculated or assumed for the sake of this example)\n",
        "error_accuracies = [0.02, 0.03, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.02, 0.02, 0.05]\n",
        "error_precisions = [0.01, 0.02, 0.01, 0.02, 0.02, 0.02, 0.01, 0.01, 0.01, 0.02, 0.05]\n",
        "error_recalls = [0.01, 0.01, 0.02, 0.01, 0.01, 0.02, 0.01, 0.01, 0.01, 0.01, 0.05]\n",
        "error_f1_scores = [0.02, 0.03, 0.02, 0.02, 0.02, 0.03, 0.02, 0.01, 0.02, 0.02, 0.05]\n",
        "\n",
        "# Metrics and labels\n",
        "metrics = [accuracy, f1_score, precision, recall]\n",
        "metrics_labels = ['Accuracy', 'F1 Score', 'Precision', 'Recall']\n",
        "metrics_errors = [error_accuracies, error_f1_scores, error_precisions, error_recalls]\n",
        "\n",
        "# Bar chart setup\n",
        "x_pos = np.arange(len(models))\n",
        "width = 0.2  # Bar width\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(30, 15))\n",
        "\n",
        "# Plot grouped bars with error bars\n",
        "for i, (metric, label, errors) in enumerate(zip(metrics, metrics_labels, metrics_errors)):\n",
        "    bar = ax.bar(\n",
        "        x_pos + i * width, metric, width * 0.8, yerr=errors,\n",
        "        label=label, alpha=0.7, ecolor='black', capsize=5\n",
        "    )\n",
        "\n",
        "    # Add labels for the bar values inside the bars\n",
        "    for j, (rect, value) in enumerate(zip(bar, metric)):\n",
        "        height = rect.get_height()\n",
        "\n",
        "        offset_x = rect.get_x() + rect.get_width() / 2.0\n",
        "        offset_y = height * 0.5\n",
        "\n",
        "        # For `0.0%` values, place the text inside the bar with a small gap\n",
        "        if value == 0.0:\n",
        "            ax.text(\n",
        "                offset_x,\n",
        "                1,  # Add a small gap above the bottom of the bar\n",
        "                f'{value:.1f}%',\n",
        "                ha='center',\n",
        "                va='center',\n",
        "                fontsize=18,\n",
        "                color='black',\n",
        "                rotation=5,  # No rotation for 0.0%\n",
        "                rotation_mode='anchor'\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            ax.text(\n",
        "                offset_x,\n",
        "                offset_y,\n",
        "                f'{value:.1f}%',\n",
        "                ha='center',\n",
        "                va='center',\n",
        "                fontsize=18,\n",
        "                color='black',\n",
        "                rotation=85,  # Rotate the non-zero text\n",
        "                rotation_mode='anchor'\n",
        "            )\n",
        "x_pos_adjusted = x_pos.copy()\n",
        "x_pos_adjusted[-1] += 0.2\n",
        "\n",
        "# Styling and layout\n",
        "ax.set_title('Metrics for orginal (Unbalanced) Data B', fontsize=24, weight='bold')\n",
        "ax.set_xlabel('Models', fontsize=20)\n",
        "ax.set_ylabel('Scores (%)', fontsize=20)\n",
        "ax.set_xticks(x_pos + width * 1.5)\n",
        "ax.set_xticklabels(models, ha= 'right', fontsize=18)\n",
        "ax.set_ylim(0, 115)\n",
        "ax.set_yticks(np.arange(0, 110, 10))\n",
        "ax.tick_params(axis='y', labelsize=24)\n",
        "ax.legend(fontsize=14, loc='upper right', bbox_to_anchor=(1, 1))\n",
        "ax.yaxis.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Adjust layout and save the figure\n",
        "plt.tight_layout()\n",
        "plt.savefig('Metrics for orginal (Unbalanced) Data B.pdf', bbox_inches='tight')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "mXvw2qr6B5w9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "sns.pairplot(df, hue = 'classification')"
      ],
      "metadata": {
        "id": "XpxuvaeyqNt1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = df.corr(numeric_only=False)\n",
        "\n",
        "# Generate a mask for the upper triangle\n",
        "mask = np.triu(np.ones_like(corr, dtype=bool))\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "plt.figure(figsize=(21, 21), dpi=700)\n",
        "\n",
        "# Draw the heatmap with the mask\n",
        "fig = sns.heatmap(corr, vmin=-0.1, vmax=1.0, mask=mask,\n",
        "                  annot=True, fmt=\".2f\", cmap='coolwarm',\n",
        "                  square=True, linewidths=0.9,\n",
        "                  cbar_kws={\"shrink\":0.6,  \"pad\":0.000001})\n",
        "\n",
        "cbar.ax.set_position([0.95, 0.1, 0.03, 0.8])\n",
        "cust_labels = df.columns.tolist()\n",
        "cust_labels[0] = ''\n",
        "fig.set_yticklabels(cust_labels)\n",
        "fig.tick_params(axis='y', which='both', length=0)\n",
        "cust_labels = df.columns.tolist()\n",
        "cust_labels[len(cust_labels)-1]= ''\n",
        "fig.set_xticklabels(cust_labels)\n",
        "fig.tick_params(axis='x', which='both', length=0)\n",
        "plt.title(\"Correlation for Features Of Dataset A\", fontsize=14)\n",
        "plt.savefig(\"Correlation for Features Of Dataset A.pdf\", bbox_inches='tight') # save figure\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "i89o_rw-r11S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gain Ratio"
      ],
      "metadata": {
        "id": "dnDk-ovutWd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_res = df.drop(columns=['classification'])\n",
        "y_res = df['classification']"
      ],
      "metadata": {
        "id": "UXJaw9dLtS3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Compute Entropy of a distribution\n",
        "def entropy(y_res):\n",
        "    value_counts = y_res.value_counts(normalize=True)\n",
        "    return -np.sum(value_counts * np.log2(value_counts + 1e-9))\n",
        "\n",
        "# Compute Information Gain\n",
        "def information_gain(X_res, y_res, feature):\n",
        "    base_entropy = entropy(y_res)\n",
        "    feature_entropy = 0\n",
        "    for value in X_res[feature].unique():\n",
        "        subset = y_res[X_res[feature] == value]\n",
        "        feature_entropy += len(subset) / len(X_res) * entropy(subset)\n",
        "    return base_entropy - feature_entropy\n",
        "\n",
        "# Compute Split Information==\n",
        "def split_information(X_res, feature):\n",
        "    value_counts = X_res[feature].value_counts(normalize=True)\n",
        "    return -np.sum(value_counts * np.log2(value_counts + 1e-9))\n",
        "\n",
        "# Compute Gain Ratio\n",
        "def gain_ratio(X_res, y_res, feature):\n",
        "    ig = information_gain(X_res, y_res, feature)\n",
        "    si = split_information(X_res, feature)\n",
        "    return ig / (si + 1e-9)\n",
        "\n",
        "# Compute Gain Ratios for all features\n",
        "gain_ratios = {feature: gain_ratio(X_res, y_res, feature) for feature in X_res.columns}\n",
        "\n",
        "# Convert to a DataFrame for easy visualization\n",
        "gain_ratio_results = pd.DataFrame(gain_ratios.items(), columns=['Feature', 'Gain Ratio'])\n",
        "gain_ratio_results = gain_ratio_results.sort_values(by=\"Gain Ratio\", ascending=False)\n",
        "\n",
        "# Display the results\n",
        "print(gain_ratio_results)"
      ],
      "metadata": {
        "id": "K_ClW1s7s_FT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the gain ratios\n",
        "plt.figure(figsize=(28, 8))\n",
        "ax1 = plt.subplot(1, 2, 1)\n",
        "gain_ratio_results.plot(kind='bar', color='skyblue', edgecolor='black', ax=ax1)\n",
        "ax1.set_title('Gain Ratio for Dataset A', fontsize=20, fontweight='bold')\n",
        "ax1.set_xlabel('Features', fontsize=16)\n",
        "ax1.set_ylabel('Gain Ratio', fontsize=16)\n",
        "ax1.set_xticklabels(gain_ratio_results['Feature'], rotation=45, ha='right', fontsize=14)\n",
        "ax1.tick_params(axis='y', labelsize=14)  # Correct way to set y-tick label size\n",
        "ax1.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"Gain Ratio for Dataset A.pdf\") # save figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "t71u4iQ7tZqa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Information Gain"
      ],
      "metadata": {
        "id": "-xIlzVbOtl50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Compute Entropy of a distribution\n",
        "def entropy(y_res):\n",
        "    value_counts = y_res.value_counts(normalize=True)\n",
        "    return -np.sum(value_counts * np.log2(value_counts + 1e-9))\n",
        "\n",
        "# Compute Information Gain\n",
        "def information_gain(X_res, y_res, feature):\n",
        "    base_entropy = entropy(y_res)\n",
        "    feature_entropy = 0\n",
        "    for value in X_res[feature].unique():\n",
        "        subset = y_res[X_res[feature] == value]\n",
        "        feature_entropy += len(subset) / len(X_res) * entropy(subset)\n",
        "    return base_entropy - feature_entropy\n",
        "\n",
        "# Compute Information Gains for all features\n",
        "information_gains = {feature: information_gain(X_res, y_res, feature) for feature in X_res.columns}\n",
        "\n",
        "# Convert to a DataFrame for easy visualization\n",
        "information_gain_results = pd.DataFrame(information_gains.items(), columns=['Feature', 'Information Gain'])\n",
        "information_gain_results = information_gain_results.sort_values(by=\"Information Gain\", ascending=False)\n",
        "\n",
        "# Display the results\n",
        "print(information_gain_results)\n"
      ],
      "metadata": {
        "id": "__7kuvZetfmN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "ig_df = information_gain_results.reset_index(drop=True)  # Reset index for clean plotting\n",
        "ig_df.columns = ['Feature', 'IG']  # Rename columns for convenience\n",
        "\n",
        "# Plot the Information Gain\n",
        "plt.figure(figsize=(12, 9))\n",
        "plt.bar(ig_df['Feature'], ig_df['IG'], color='green')\n",
        "plt.xlabel('Features', fontsize=20)\n",
        "plt.xticks(fontsize=16, rotation=45)\n",
        "plt.ylabel('Information Gain', fontsize=20)\n",
        "plt.title('Information Gain for Dataset A', fontsize=24)\n",
        "plt.tight_layout()  # To ensure proper spacing for labels\n",
        "\n",
        "# Save the plot as a PDF file\n",
        "plt.savefig(\"Information Gain for Dataset A.pdf\", bbox_inches='tight')\n",
        "\n",
        "# Display the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "pcsqfwJjtpbk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}